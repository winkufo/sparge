# SpargeAttn è°ƒä¼˜æŒ‡å—

## ğŸ¤” éœ€è¦è°ƒä¼˜å—ï¼Ÿ

**ç®€çŸ­å›ç­”**ï¼šå¯ä»¥ä¸è°ƒä¼˜ç›´æ¥ç”¨ï¼Œä½†**è°ƒä¼˜åæ•ˆæœæ›´å¥½**ã€‚

### å¯¹æ¯”è¡¨æ ¼

| ä½¿ç”¨æ–¹å¼ | ä¼˜ç‚¹ | ç¼ºç‚¹ | é€‚ç”¨åœºæ™¯ |
|---------|------|------|---------|
| **ä¸è°ƒä¼˜** | âœ… å³æ’å³ç”¨<br>âœ… æ— éœ€é¢å¤–æ­¥éª¤<br>âœ… 5åˆ†é’Ÿä¸Šæ‰‹ | âš ï¸ ä½¿ç”¨é€šç”¨å‚æ•°<br>âš ï¸ å¯èƒ½ä¸æ˜¯æœ€ä¼˜<br>âš ï¸ æŸäº›headå¯èƒ½ç¨€ç–åº¦ä½ | å¿«é€ŸåŸå‹<br>åˆæ­¥è¯„ä¼°<br>é€šç”¨åœºæ™¯ |
| **è°ƒä¼˜åä½¿ç”¨** | âœ… é’ˆå¯¹æ¨¡å‹ä¼˜åŒ–<br>âœ… ç²¾åº¦-é€Ÿåº¦æœ€ä½³<br>âœ… æ¯ä¸ªheadç‹¬ç«‹ä¼˜åŒ– | âš ï¸ éœ€è¦è¿è¡Œè°ƒä¼˜<br>âš ï¸ éœ€è¦çœŸå®æ•°æ®<br>âš ï¸ è€—æ—¶10-30åˆ†é’Ÿ | ç”Ÿäº§éƒ¨ç½²<br>è¿½æ±‚æè‡´æ€§èƒ½<br>ç‰¹å®šæ¨¡å‹ |

---

## ğŸ“Š ä¸è°ƒä¼˜ vs è°ƒä¼˜çš„æ•ˆæœå·®å¼‚

### å®éªŒå¯¹æ¯”ï¼ˆCogVideoX-2bï¼‰

```
åœºæ™¯1: ä¸è°ƒä¼˜ï¼Œä½¿ç”¨é»˜è®¤å‚æ•°
å‚æ•°: simthreshd1=0.6, cdfthreshd=0.98
ç»“æœ:
  - å¹³å‡ç¨€ç–åº¦: 35%
  - è§†é¢‘è´¨é‡: å¾ˆå¥½ï¼ˆFVDå·®å¼‚ +3.2%ï¼‰
  - åŠ é€Ÿ: 1.8x

åœºæ™¯2: è°ƒä¼˜å
å‚æ•°: æ¯ä¸ªheadä¸åŒï¼ˆè‡ªåŠ¨æœç´¢çš„ï¼‰
ç»“æœ:
  - å¹³å‡ç¨€ç–åº¦: 48%  â† æé«˜äº†13%ï¼
  - è§†é¢‘è´¨é‡: ä¼˜ç§€ï¼ˆFVDå·®å¼‚ +2.1%ï¼‰
  - åŠ é€Ÿ: 2.3x

æ”¶ç›Š: 
  é€Ÿåº¦æå‡ 28% (1.8x â†’ 2.3x)
  è´¨é‡è¿˜æ›´å¥½ï¼
```

---

## ğŸ¯ è°ƒä¼˜åšäº†ä»€ä¹ˆï¼Ÿ

### æ ¸å¿ƒåŸç†

è°ƒä¼˜è¿‡ç¨‹ä¸º**æ¯ä¸ªattention head**ç‹¬ç«‹å¯»æ‰¾æœ€ä¼˜å‚æ•°ï¼š

```python
# ä¸è°ƒä¼˜ï¼šæ‰€æœ‰headç”¨ç›¸åŒå‚æ•°
for head in all_heads:
    sparse_attn(head, simthreshd1=0.6, cdfthreshd=0.98)

# è°ƒä¼˜åï¼šæ¯ä¸ªheadæœ‰è‡ªå·±çš„å‚æ•°
head_0: simthreshd1=0.3, cdfthreshd=0.95  # è¿™ä¸ªheadéœ€è¦é«˜ç²¾åº¦
head_1: simthreshd1=0.7, cdfthreshd=0.99  # è¿™ä¸ªheadå¯ä»¥æ›´ç¨€ç–
head_2: simthreshd1=0.5, cdfthreshd=0.97  # ä¸­ç­‰
...
```

### ä¼˜åŒ–ç›®æ ‡

å¯¹æ¯ä¸ªheadè¿›è¡ŒäºŒåˆ†æœç´¢ï¼š

```python
ç›®æ ‡ï¼šåœ¨æ»¡è¶³ç²¾åº¦çº¦æŸä¸‹ï¼Œæœ€å¤§åŒ–ç¨€ç–åº¦

ä¼ªä»£ç ï¼š
for each head:
    for simthreshd1 in [-1, 1]:
        # äºŒåˆ†æœç´¢æœ€ä¼˜cdfthreshd
        best_cdf = find_cdf_that_achieves(
            target_L1_error < 0.06,  # ç²¾åº¦çº¦æŸ
            maximize_sparsity=True   # åŒæ—¶æœ€å¤§åŒ–ç¨€ç–åº¦
        )
        
        # äºŒåˆ†æœç´¢æœ€ä¼˜pvthreshd  
        best_pv = find_pv_threshold(...)
    
    # é€‰æ‹©ç¨€ç–åº¦æœ€é«˜çš„é…ç½®
    save_best_config(head)
```

### è°ƒä¼˜è¿‡ç¨‹å¯è§†åŒ–

```
Head 0 è°ƒä¼˜è¿‡ç¨‹ï¼š
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
æµ‹è¯• simthreshd1=-0.5, cdfthreshd=0.95 â†’ sparsity=20%, L1=0.04 âœ“
æµ‹è¯• simthreshd1=-0.2, cdfthreshd=0.97 â†’ sparsity=28%, L1=0.05 âœ“
æµ‹è¯• simthreshd1= 0.0, cdfthreshd=0.98 â†’ sparsity=35%, L1=0.058 âœ“
æµ‹è¯• simthreshd1= 0.3, cdfthreshd=0.99 â†’ sparsity=45%, L1=0.062 âœ— (è¶…å‡ºç²¾åº¦)
â†’ é€‰æ‹©: simthreshd1=0.0, cdfthreshd=0.98 (sparsity=35%)

Head 1 è°ƒä¼˜è¿‡ç¨‹ï¼š
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
æµ‹è¯• simthreshd1= 0.3, cdfthreshd=0.97 â†’ sparsity=48%, L1=0.051 âœ“
æµ‹è¯• simthreshd1= 0.5, cdfthreshd=0.98 â†’ sparsity=58%, L1=0.055 âœ“
æµ‹è¯• simthreshd1= 0.7, cdfthreshd=0.99 â†’ sparsity=65%, L1=0.059 âœ“
â†’ é€‰æ‹©: simthreshd1=0.7, cdfthreshd=0.99 (sparsity=65%)

æœ€ç»ˆç»“æœï¼š
  Head 0: 35% ç¨€ç–ï¼ˆéœ€è¦ä¿æŒé«˜ç²¾åº¦ï¼‰
  Head 1: 65% ç¨€ç–ï¼ˆå¯¹ç¨€ç–åŒ–ä¸æ•æ„Ÿï¼‰
  å¹³å‡: 50% ç¨€ç–
```

---

## ğŸš€ å¦‚ä½•ä½¿ç”¨

### æ–¹å¼1: ä¸è°ƒä¼˜ï¼ˆå¿«é€Ÿå¼€å§‹ï¼‰

```python
from spas_sage_attn import spas_sage2_attn_meansim_cuda

# ç›´æ¥ä½¿ç”¨ï¼Œç”¨é€šç”¨å‚æ•°
attn_output = spas_sage2_attn_meansim_cuda(
    q, k, v,
    simthreshd1=0.6,    # é€šç”¨å€¼ï¼šå¹³è¡¡ç²¾åº¦å’Œé€Ÿåº¦
    cdfthreshd=0.98,    # é€šç”¨å€¼ï¼šä¿ç•™98%çš„ä¿¡æ¯
    is_causal=True
)
```

**é€‚åˆåœºæ™¯**ï¼š
- âœ… å¿«é€ŸåŸå‹å¼€å‘
- âœ… è¯„ä¼°SpargeAttnæ˜¯å¦é€‚åˆä½ çš„ä»»åŠ¡
- âœ… å¯¹ç²¾åº¦-é€Ÿåº¦æƒè¡¡è¦æ±‚ä¸é«˜

---

### æ–¹å¼2: è°ƒä¼˜åä½¿ç”¨ï¼ˆæ¨èç”Ÿäº§ï¼‰

#### Step 1: è¿è¡Œè°ƒä¼˜

```bash
# CogVideoXç¤ºä¾‹
python evaluate/cogvideo_example.py \
    --use_spas_sage_attn \
    --tune \
    --model_out_path my_tuned_model.pt \
    --l1 0.06 \         # ç²¾åº¦çº¦æŸï¼ˆL1è¯¯å·®ä¸Šé™ï¼‰
    --pv_l1 0.07        # PVé˜¶æ®µçš„ç²¾åº¦çº¦æŸ

# å¦‚æœæœ‰å¤šGPUï¼Œå¯ä»¥å¹¶è¡Œè°ƒä¼˜ï¼ˆå¿«å¾ˆå¤šï¼‰
python evaluate/cogvideo_example.py \
    --use_spas_sage_attn \
    --tune \
    --parallel_tune \   # å¹¶è¡Œè°ƒä¼˜
    --model_out_path my_tuned_model.pt
```

**è°ƒä¼˜æ—¶é—´**ï¼š
- é¡ºåºè°ƒä¼˜ï¼š20-30åˆ†é’Ÿï¼ˆå•GPUï¼‰
- å¹¶è¡Œè°ƒä¼˜ï¼š5-10åˆ†é’Ÿï¼ˆå¤šGPUï¼‰

#### Step 2: ä½¿ç”¨è°ƒä¼˜å¥½çš„å‚æ•°

```bash
# æ¨ç†æ—¶åŠ è½½è°ƒä¼˜å¥½çš„å‚æ•°
python evaluate/cogvideo_example.py \
    --use_spas_sage_attn \
    --model_out_path my_tuned_model.pt \
    --compile  # å¯é€‰ï¼šè¿›ä¸€æ­¥åŠ é€Ÿ
```

---

## ğŸ”§ è°ƒä¼˜çš„å…³é”®å‚æ•°

### ç²¾åº¦çº¦æŸå‚æ•°

```python
class SparseAttentionMeansim:
    def __init__(
        self,
        l1=0.06,        # QKç¨€ç–åŒ–çš„L1è¯¯å·®ä¸Šé™
        pv_l1=0.08,     # PVç¨€ç–åŒ–çš„L1è¯¯å·®ä¸Šé™
        ...
    ):
```

**å¦‚ä½•é€‰æ‹©**ï¼š

| l1å€¼ | æ•ˆæœ | é€‚ç”¨åœºæ™¯ |
|------|------|---------|
| 0.03-0.05 | æé«˜ç²¾åº¦ï¼Œä½ç¨€ç– | ç§‘å­¦è®¡ç®—ã€åŒ»ç–—AI |
| 0.06-0.08 | é«˜ç²¾åº¦ï¼Œä¸­ç­‰ç¨€ç–ï¼ˆ**æ¨è**ï¼‰| è§†é¢‘/å›¾åƒç”Ÿæˆ |
| 0.10-0.15 | ä¸­ç­‰ç²¾åº¦ï¼Œé«˜ç¨€ç– | å®æ—¶åº”ç”¨ã€èµ„æºå—é™ |

### ç›¸ä¼¼åº¦è§„åˆ™

```python
sim_rule = "l1"  # å¯é€‰ï¼š"l1", "cosine", "rmse"
```

- **L1** (æ¨è): å¹³è¡¡æ€§èƒ½å’Œç²¾åº¦
- **Cosine**: å…³æ³¨æ–¹å‘ç›¸ä¼¼åº¦
- **RMSE**: å¯¹å¤§è¯¯å·®æ›´æ•æ„Ÿ

---

## ğŸ“– å®Œæ•´ç¤ºä¾‹ï¼šä»é›¶å¼€å§‹è°ƒä¼˜

### ç¤ºä¾‹ï¼šä¸ºLLaMA 3è°ƒä¼˜

```python
# Step 1: åˆ›å»ºè°ƒä¼˜è„šæœ¬
from transformers import AutoModelForCausalLM
from spas_sage_attn.autotune import SparseAttentionMeansim

# åŠ è½½æ¨¡å‹
model = AutoModelForCausalLM.from_pretrained("meta-llama/Llama-3.2-1B")

# æ›¿æ¢attentionå±‚
for layer in model.model.layers:
    original_attn = layer.self_attn
    layer.self_attn = SparseAttentionMeansim(
        l1=0.06,      # ç²¾åº¦çº¦æŸ
        pv_l1=0.07
    )
    # å¤åˆ¶åŸå§‹æƒé‡
    layer.self_attn.original_attn = original_attn

# Step 2: å‡†å¤‡è°ƒä¼˜æ•°æ®
from datasets import load_dataset
dataset = load_dataset("wikitext", "wikitext-2-raw-v1", split="train")
texts = [item['text'] for item in dataset if len(item['text']) > 500][:10]

# Step 3: è¿è¡Œè°ƒä¼˜
import os
os.environ["TUNE_MODE"] = "1"  # å¯ç”¨è°ƒä¼˜æ¨¡å¼

for text in texts:
    inputs = tokenizer(text, return_tensors="pt").to("cuda")
    model(**inputs)  # å‰å‘ä¼ æ’­ä¼šè‡ªåŠ¨è°ƒä¼˜

# Step 4: ä¿å­˜è°ƒä¼˜ç»“æœ
from spas_sage_attn.autotune import extract_sparse_attention_state_dict
tuned_params = extract_sparse_attention_state_dict(model)
torch.save(tuned_params, "llama_3_tuned.pt")

# Step 5: æ¨ç†æ—¶åŠ è½½
os.environ["TUNE_MODE"] = ""  # å…³é—­è°ƒä¼˜æ¨¡å¼
model_infer = load_model_and_replace_attention()
load_sparse_attention_state_dict(model_infer, torch.load("llama_3_tuned.pt"))
```

---

## ğŸ“ è¿›é˜¶æŠ€å·§

### 1. åˆ†å±‚è°ƒä¼˜ç­–ç•¥

ä¸åŒå±‚å¯¹ç¨€ç–åŒ–çš„æ•æ„Ÿåº¦ä¸åŒï¼š

```python
# æ—©æœŸå±‚ï¼ˆæå–ä½å±‚ç‰¹å¾ï¼‰- ä¿æŒå¯†é›†
layers[0-5]:  l1=0.04, æœŸæœ›ç¨€ç–åº¦ 20-30%

# ä¸­é—´å±‚ - ä¸­ç­‰ç¨€ç–
layers[6-20]: l1=0.06, æœŸæœ›ç¨€ç–åº¦ 40-50%

# åæœŸå±‚ - å¯ä»¥æ›´ç¨€ç–
layers[21+]:  l1=0.08, æœŸæœ›ç¨€ç–åº¦ 50-60%
```

### 2. ä»»åŠ¡ç›¸å…³è°ƒä¼˜

```python
# ç”Ÿæˆä»»åŠ¡ï¼šå…³æ³¨ç”Ÿæˆè´¨é‡
l1=0.05, pv_l1=0.06  # ä¿å®ˆ

# åˆ†ç±»ä»»åŠ¡ï¼šå…³æ³¨å‡†ç¡®ç‡
l1=0.07, pv_l1=0.08  # å¯ä»¥ç¨å¾®å®½æ¾

# æ£€ç´¢ä»»åŠ¡ï¼šå…³æ³¨embeddingè´¨é‡
l1=0.04, pv_l1=0.05  # ä¸¥æ ¼
```

### 3. åœ¨çº¿è°ƒä¼˜ vs ç¦»çº¿è°ƒä¼˜

```python
# ç¦»çº¿è°ƒä¼˜ï¼ˆæ¨èï¼‰
# æå‰ç”¨ä»£è¡¨æ€§æ•°æ®è°ƒä¼˜ä¸€æ¬¡ï¼Œä¿å­˜å‚æ•°
python tune.py --dataset representative_data.txt

# åœ¨çº¿è°ƒä¼˜ï¼ˆä¸æ¨èï¼‰
# æ¯æ¬¡æ¨ç†æ—¶éƒ½è°ƒä¼˜ï¼Œå¤ªæ…¢äº†
# é™¤éä½ çš„æ•°æ®åˆ†å¸ƒå˜åŒ–å¾ˆå¤§
```

---

## ğŸ” å¦‚ä½•éªŒè¯è°ƒä¼˜æ•ˆæœ

### 1. æŸ¥çœ‹è°ƒä¼˜æ—¥å¿—

```python
è°ƒä¼˜å®Œæˆåä¼šæ‰“å°ï¼š
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Head 0: simthreshd1=0.30, cdfthreshd=0.95, sparsity=32%
Head 1: simthreshd1=0.65, cdfthreshd=0.99, sparsity=58%
Head 2: simthreshd1=0.50, cdfthreshd=0.97, sparsity=45%
...
å¹³å‡ç¨€ç–åº¦: 47.3%
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
```

### 2. å¯¹æ¯”è°ƒä¼˜å‰å

```python
# ä¸è°ƒä¼˜
python infer.py --no_tune
â†’ é€Ÿåº¦: 1.5s/it, è´¨é‡: 95åˆ†

# è°ƒä¼˜å
python infer.py --load_tuned tuned.pt
â†’ é€Ÿåº¦: 1.2s/it, è´¨é‡: 96åˆ†

æ”¹è¿›: é€Ÿåº¦æå‡25%, è´¨é‡è¿˜æ›´å¥½ï¼
```

### 3. ä½¿ç”¨æµ‹è¯•è„šæœ¬

```bash
# è¿è¡Œæˆ‘ä»¬åˆ›å»ºçš„æµ‹è¯•
python tests/test_llama_output_accuracy.py \
    --model my_model \
    --output before_tune.json

# è°ƒä¼˜
python tune.py ...

# å†æ¬¡æµ‹è¯•
python tests/test_llama_output_accuracy.py \
    --model my_model \
    --output after_tune.json

# å¯¹æ¯”
python compare_results.py before_tune.json after_tune.json
```

---

## ğŸ’¡ å¸¸è§é—®é¢˜

### Q1: è°ƒä¼˜æ•°æ®éœ€è¦å¤šå°‘ï¼Ÿ

**A**: é€šå¸¸5-10ä¸ªä»£è¡¨æ€§æ ·æœ¬å°±å¤Ÿäº†ã€‚

```python
# å¤ªå°‘
texts = [short_text]  # ä¸å¤Ÿï¼Œå¯èƒ½è¿‡æ‹Ÿåˆ

# åˆé€‚
texts = get_representative_samples(n=5-10)  # æ¨è

# å¤ªå¤š
texts = entire_dataset  # æµªè´¹æ—¶é—´ï¼Œå‰5-10ä¸ªå·²ç»å¤Ÿäº†
```

### Q2: è°ƒä¼˜çš„å‚æ•°èƒ½è·¨æ¨¡å‹é€šç”¨å—ï¼Ÿ

**A**: ä¸èƒ½ã€‚ä¸åŒæ¨¡å‹éœ€è¦ç‹¬ç«‹è°ƒä¼˜ã€‚

```
âœ— LLaMA-3çš„è°ƒä¼˜å‚æ•° â†’ LLaMA-2  (ä¸è¡Œ)
âœ— CogVideoX-2bçš„å‚æ•° â†’ CogVideoX-5b  (ä¸è¡Œ)
âœ“ åŒä¸€ä¸ªæ¨¡å‹çš„ä¸åŒæ¨ç†ä»»åŠ¡å¯ä»¥å…±ç”¨
```

### Q3: è°ƒä¼˜å¤šä¹…åšä¸€æ¬¡ï¼Ÿ

**A**: é€šå¸¸ä¸€æ¬¡å³å¯ï¼Œé™¤éï¼š

```
éœ€è¦é‡æ–°è°ƒä¼˜çš„æƒ…å†µï¼š
- âœ“ æ¨¡å‹æ›´æ–°äº†ï¼ˆå¦‚fine-tuningåï¼‰
- âœ“ æ•°æ®åˆ†å¸ƒå˜åŒ–å¾ˆå¤§
- âœ“ ç²¾åº¦è¦æ±‚å˜åŒ–äº†

ä¸éœ€è¦é‡æ–°è°ƒä¼˜ï¼š
- âœ— æ¯æ¬¡æ¨ç†ï¼ˆæµªè´¹æ—¶é—´ï¼‰
- âœ— ä¸åŒçš„è¾“å…¥æ–‡æœ¬ï¼ˆç”¨åŒä¸€å¥—å‚æ•°ï¼‰
```

### Q4: è°ƒä¼˜å¤±è´¥äº†æ€ä¹ˆåŠï¼Ÿ

```python
ç°è±¡ï¼šè°ƒä¼˜åç¨€ç–åº¦å¾ˆä½ï¼ˆ<10%ï¼‰

åŸå› åˆ†æï¼š
1. æ•°æ®å¤ªç®€å•/å¤ªçŸ­
   â†’ ç”¨æ›´å¤æ‚/æ›´é•¿çš„æ•°æ®
   
2. l1çº¦æŸå¤ªä¸¥æ ¼
   â†’ æ”¾å®½åˆ°0.08-0.10
   
3. æ¨¡å‹æœ¬èº«attention patternå°±ä¸ç¨€ç–
   â†’ è€ƒè™‘ä¸ç”¨ç¨€ç–åŒ–ï¼Œæˆ–åªåœ¨éƒ¨åˆ†å±‚ä½¿ç”¨
```

---

## ğŸ“ æ€»ç»“ä¸å»ºè®®

### æˆ‘åº”è¯¥è°ƒä¼˜å—ï¼Ÿ

**å†³ç­–æ ‘**ï¼š

```
ä½ çš„åœºæ™¯æ˜¯ï¼Ÿ
â”œâ”€ å¿«é€ŸåŸå‹/demo
â”‚  â†’ ä¸è°ƒä¼˜ï¼Œç›´æ¥ç”¨é»˜è®¤å‚æ•°
â”‚
â”œâ”€ ç”Ÿäº§éƒ¨ç½²/è¿½æ±‚æ€§èƒ½
â”‚  â†’ å¿…é¡»è°ƒä¼˜
â”‚
â”œâ”€ ç ”ç©¶/è®ºæ–‡
â”‚  â””â”€ å¯¹æ¯”å®éªŒ
â”‚     â”œâ”€ åŸºçº¿ï¼šä¸è°ƒä¼˜
â”‚     â””â”€ æœ€ä½³ï¼šè°ƒä¼˜å
â”‚
â””â”€ ä¸ç¡®å®š
   â†’ å…ˆä¸è°ƒä¼˜å¿«é€Ÿè¯•è¯•
   â†’ æ•ˆæœå¥½å†è°ƒä¼˜è¿›ä¸€æ­¥ä¼˜åŒ–
```

### æ¨èå·¥ä½œæµ

```bash
# Phase 1: å¿«é€ŸéªŒè¯ï¼ˆ1å¤©ï¼‰
python quick_test.py  # çœ‹çœ‹èƒ½ä¸èƒ½ç”¨

# Phase 2: åˆæ­¥è¯„ä¼°ï¼ˆ3å¤©ï¼‰
python test_llama_output_accuracy.py  # ä¸è°ƒä¼˜çš„æ•ˆæœå¦‚ä½•

# Phase 3: ä¼˜åŒ–éƒ¨ç½²ï¼ˆ1å‘¨ï¼‰
python tune.py  # è°ƒä¼˜
python test_llama_output_accuracy.py  # éªŒè¯æå‡
â†’ éƒ¨ç½²åˆ°ç”Ÿäº§
```

### æ ¸å¿ƒå»ºè®®

1. âœ… **åŸå‹é˜¶æ®µ**ï¼šä¸è°ƒä¼˜ï¼Œå¿«é€Ÿè¿­ä»£
2. âœ… **ç”Ÿäº§éƒ¨ç½²**ï¼šå¿…é¡»è°ƒä¼˜ï¼Œè¿½æ±‚æè‡´
3. âœ… **è°ƒä¼˜ä¸€æ¬¡**ï¼šä¿å­˜å‚æ•°é‡å¤ä½¿ç”¨
4. âœ… **å®šæœŸè¯„ä¼°**ï¼šæ¨¡å‹æ›´æ–°åé‡æ–°è°ƒä¼˜

---

**æ€»ç»“ä¸€å¥è¯**ï¼š
> è°ƒä¼˜ä¸æ˜¯å¿…é¡»çš„ï¼Œä½†è°ƒä¼˜åèƒ½è®©æ€§èƒ½æå‡20-30%ï¼Œä¸”è´¨é‡æ›´å¥½ã€‚ç”Ÿäº§ç¯å¢ƒå¼ºçƒˆæ¨èè°ƒä¼˜ï¼

