# æ¨¡å‹é€‚é…è¯´æ˜

æœ¬ç›®å½•åŒ…å«äº†ä¸ºä¸åŒæ¨¡å‹é€‚é…SpargeAttnçš„ä»£ç ã€‚

## ğŸ“ æ–‡ä»¶è¯´æ˜

| æ–‡ä»¶ | æ¨¡å‹ç±»å‹ | æ³¨æ„åŠ›ç±»å‹ | ç‰¹æ®Šå¤„ç† |
|------|---------|-----------|---------|
| `modify_cogvideo.py` | CogVideoX (è§†é¢‘ç”Ÿæˆ) | éå› æœ | Attention Processor |
| `modify_llama.py` | LLaMA (è¯­è¨€æ¨¡å‹) | å› æœ | GQA + RoPE |
| `modify_flux.py` | Flux (å›¾åƒç”Ÿæˆ) | éå› æœ | - |
| `modify_hunyuan.py` | HunyuanDiT (å›¾åƒç”Ÿæˆ) | éå› æœ | - |
| `modify_wan.py` | Wan2V (è§†é¢‘ç”Ÿæˆ) | éå› æœ | - |

---

## ğŸ”§ LLaMAé€‚é…è¯´æ˜

### å…³é”®ä¿®æ­£

æ ¹æ®[transformerså®˜æ–¹å®ç°](https://github.com/huggingface/transformers/blob/main/src/transformers/models/llama/modeling_llama.py)ï¼Œä¿®æ­£äº†ä»¥ä¸‹é—®é¢˜ï¼š

#### 1. `hidden_size` å±æ€§

**é—®é¢˜**ï¼šLLamaAttentionæ²¡æœ‰ç›´æ¥çš„`hidden_size`å±æ€§

```python
# âŒ é”™è¯¯
self.hidden_size = original_attn.hidden_size  # ä¸å­˜åœ¨

# âœ… æ­£ç¡®
self.hidden_size = original_attn.config.hidden_size  # ä»configè·å–
```

#### 2. `apply_rotary_pos_emb` å¯¼å…¥

**é—®é¢˜**ï¼šéœ€è¦ä»transformerså¯¼å…¥

```python
# âœ… æ­£ç¡®å¯¼å…¥
from transformers.models.llama.modeling_llama import apply_rotary_pos_emb
```

#### 3. ç‰ˆæœ¬å…¼å®¹æ€§

ä¸åŒç‰ˆæœ¬çš„transformers APIå¯èƒ½ä¸åŒï¼š

```python
# å…¼å®¹å¤„ç†
try:
    # æ–°ç‰ˆæœ¬API
    cos, sin = self.rotary_emb(value_states, position_ids)
    query_states, key_states = apply_rotary_pos_emb(q, k, cos, sin)
except:
    # æ—§ç‰ˆæœ¬API  
    cos, sin = self.rotary_emb(value_states, seq_len=kv_seq_len)
    query_states, key_states = apply_rotary_pos_emb(q, k, cos, sin, position_ids)
```

---

## âœ… éªŒè¯å®ç°

è¿è¡ŒéªŒè¯è„šæœ¬ç¡®ä¿å®ç°æ­£ç¡®ï¼š

```bash
python evaluate/verify_llama_implementation.py
```

**é¢„æœŸè¾“å‡º**ï¼š
```
éªŒè¯LLaMAç¨€ç–åŒ–å®ç°
============================================================

[1/5] åŠ è½½åŸå§‹æ¨¡å‹...
âœ“ æ¨¡å‹åŠ è½½æˆåŠŸ

[2/5] æ£€æŸ¥æ¨¡å‹ç»“æ„...
âœ“ æ‰¾åˆ° 32 å±‚
Attentionç±»å‹: LlamaAttention
Attentionå±æ€§:
  âœ“ config: LlamaConfig
  âœ“ num_heads: 32
  âœ“ head_dim: 64
  âœ“ num_key_value_heads: 8
  âœ“ num_key_value_groups: 4
  âœ“ hidden_size (from config): 2048

[3/5] åº”ç”¨ç¨€ç–åŒ–...
âœ“ Replaced layer 0 attention with sparse version
âœ“ Replaced layer 1 attention with sparse version
...
æ€»å…±æ›¿æ¢äº† 32/32 ä¸ªattentionå±‚
âœ“ ç¨€ç–åŒ–åº”ç”¨æˆåŠŸ

[4/5] æµ‹è¯•å‰å‘ä¼ æ’­...
âœ“ å‰å‘ä¼ æ’­æˆåŠŸ
  è¾“å‡ºå½¢çŠ¶: torch.Size([1, 7, 32000])
  è¾“å‡ºèŒƒå›´: [-15.23, 12.45]

[5/5] æµ‹è¯•ç”Ÿæˆ...
âœ“ ç”ŸæˆæˆåŠŸ
  è¾“å…¥: The capital of France is
  è¾“å‡º: The capital of France is Paris.

============================================================
âœ“ æ‰€æœ‰éªŒè¯é€šè¿‡ï¼LLaMAå®ç°æ­£ç¡®
============================================================
```

---

## ğŸ¯ ä¸åŒæ¨¡å‹çš„é€‚é…è¦ç‚¹

### CogVideoX

```python
# ç‰¹ç‚¹ï¼š
- ä½¿ç”¨Attention Processoræœºåˆ¶
- éå› æœattention (is_causal=False)
- æœ‰textå’Œimageä¸¤éƒ¨åˆ†ï¼ˆRoPEåªåœ¨imageéƒ¨åˆ†ï¼‰

# å®ç°æ–¹å¼ï¼š
class SageAttnCogVideoXAttnProcessor:
    def __call__(self, attn, hidden_states, ...):
        # åœ¨processorä¸­å¤„ç†attention
        ...

block.attn1.set_processor(processor)
```

### LLaMA

```python
# ç‰¹ç‚¹ï¼š
- ç›´æ¥çš„Attentionæ¨¡å—
- å› æœattention (is_causal=True)
- GQA (Grouped Query Attention)
- RoPEåº”ç”¨åœ¨å…¨åºåˆ—

# å®ç°æ–¹å¼ï¼š
class SparseLlamaAttention(nn.Module):
    def __init__(self, original_attn):
        # å¤åˆ¶æ‰€æœ‰projectionå’Œrotary_emb
        ...
    
    def forward(self, hidden_states, ...):
        # å®Œæ•´å®ç°attentioné€»è¾‘
        ...

layer.self_attn = SparseLlamaAttention(original_attn)
```

### å…³é”®å·®å¼‚æ€»ç»“

| æ–¹é¢ | CogVideoX | LLaMA |
|------|-----------|-------|
| **æ›¿æ¢æ–¹å¼** | è®¾ç½®processor | æ›¿æ¢æ•´ä¸ªæ¨¡å— |
| **is_causal** | False | True |
| **ç‰¹æ®Šç»„ä»¶** | RoPEéƒ¨åˆ†åº”ç”¨ | GQA + RoPEå…¨åº”ç”¨ |
| **éš¾åº¦** | ç®€å• | ä¸­ç­‰ |

---

## ğŸ” è°ƒè¯•æŠ€å·§

### å¦‚æœé‡åˆ°å±æ€§é”™è¯¯

```python
# æ£€æŸ¥å¯¹è±¡æœ‰å“ªäº›å±æ€§
obj = model.model.layers[0].self_attn
print(dir(obj))

# æ£€æŸ¥config
print(obj.config.__dict__)
```

### å¦‚æœé‡åˆ°ç»´åº¦é”™è¯¯

```python
# æ‰“å°ä¸­é—´tensorçš„å½¢çŠ¶
print(f"Q shape: {query_states.shape}")
print(f"K shape: {key_states.shape}")
print(f"V shape: {value_states.shape}")
```

### å¦‚æœé‡åˆ°RoPEé”™è¯¯

```python
# æ£€æŸ¥transformersç‰ˆæœ¬
import transformers
print(f"transformers version: {transformers.__version__}")

# æ¨èç‰ˆæœ¬: >= 4.36.0
```

---

## ğŸ“š å‚è€ƒèµ„æº

- [Transformers LLaMAå®ç°](https://github.com/huggingface/transformers/blob/main/src/transformers/models/llama/modeling_llama.py)
- [CogVideoXå®ç°](https://github.com/huggingface/diffusers/blob/main/src/diffusers/models/transformers/cogvideox_transformer_3d.py)
- [SpargeAttnè®ºæ–‡](https://arxiv.org/abs/2502.18137)

